{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/gdp.pkl\", \"rb\") as file:\n",
    "  gdp = pickle.load(file)\n",
    "\n",
    "with open(\"../data/raw/naics_occupation.pkl\", \"rb\") as file:\n",
    "  occ = pickle.load(file)\n",
    "\n",
    "with open(\"../data/raw/naics_pattern.pkl\", \"rb\") as file:\n",
    "  patterns = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Droppings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cols to drop\n",
    "gdp_cols_to_drop = [\"Region\", \"TableName\", \"LineCode\", \"Unit\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"] \n",
    "occ_cols_to_drop = [\"State_GEOID\", \"NAICS_TITLE\"]\n",
    "pattern_cols_to_drop = [\"State_GEOID\", \"County_GEOID\", \"DESCRIPTION\", \"qp1_nf\", \"qp1\"]\n",
    "\n",
    "# Establish filters\n",
    "fips_filter = \"|\".join([\"^0\", \"0$\", \"999$\"])\n",
    "naics_filter = \"|\".join([\"^11\", \"^21\", \"^22\", \"^23\", \"^31\", \"^32\", \"^33\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cols\n",
    "gdp = gdp.drop(gdp_cols_to_drop, axis=1)\n",
    "occ = occ.drop(occ_cols_to_drop, axis=1)\n",
    "patterns = patterns.drop(pattern_cols_to_drop, axis=1)\n",
    "\n",
    "# Drop unnecessary FIPS\n",
    "gdp = gdp.loc[gdp[\"FIPS\"] < 90000]\n",
    "gdp = gdp.loc[~gdp[\"FIPS\"].astype(str).str.contains(fips_filter)]\n",
    "\n",
    "occ = occ.loc[occ[\"FIPS\"] < 90000]\n",
    "occ = occ.loc[~occ[\"FIPS\"].astype(str).str.contains(fips_filter)]\n",
    "\n",
    "patterns = patterns.loc[patterns[\"FIPS\"] < 90000]\n",
    "patterns = patterns.loc[~patterns[\"FIPS\"].astype(str).str.contains(fips_filter)]\n",
    "\n",
    "# Rename columns for uniformity\n",
    "gdp = gdp.rename(columns={\"IndustryClassification\": \"naics\", \"2022\": \"gdp\"})\n",
    "\n",
    "# Drop uninteresting NAICS\n",
    "gdp = gdp.loc[gdp[\"naics\"].str.contains(naics_filter)]\n",
    "gdp = gdp.loc[~gdp[\"naics\"].isin([\"11,21\", \"22,48-49\", \"31-33,51\"])]\n",
    "occ = occ.loc[occ[\"naics\"].str.contains(naics_filter)]\n",
    "patterns = patterns.loc[patterns[\"naics\"].str.contains(naics_filter)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new cols\n",
    "### Compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress NAICS functions\n",
    "def map_naics_code(naics_code):\n",
    "  code_prefix = int(naics_code[:3])\n",
    "\n",
    "  if code_prefix < 310: \n",
    "    return str(code_prefix)[:2]\n",
    "  else:\n",
    "    if code_prefix == 321 or ( 327 <= code_prefix <= 339):\n",
    "      return \"321,327-339\"\n",
    "    elif (311 <=code_prefix <= 316) or (322 <= code_prefix <= 326):\n",
    "      return \"311-316,322-326\"\n",
    "    else:\n",
    "      return \"31-33\"\n",
    "\n",
    "# Apply function\n",
    "occ[\"naics_2\"] = occ[\"naics\"].apply(map_naics_code)\n",
    "patterns[\"naics_2\"] = patterns[\"naics\"].apply(map_naics_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group for naics and fips\n",
    "gdp_naics = gdp.groupby([\"naics\"])[\"gdp\"].sum()\n",
    "gdp_fips = gdp.groupby([\"FIPS\"])[\"gdp\"].sum()\n",
    "\n",
    "# Series to DataFrame\n",
    "gdp_naics = gdp_naics.reset_index()\n",
    "gdp_fips = gdp_fips.reset_index()\n",
    "\n",
    "# Rename the corresponding gdp cols\n",
    "gdp_naics.rename(columns={\"gdp\": \"gdp_naics\"}, inplace=True)\n",
    "gdp_fips.rename(columns={\"gdp\": \"gdp_fips\"}, inplace=True)\n",
    "\n",
    "# Merge gdp cols\n",
    "gdp = pd.merge(gdp, gdp_naics, on=\"naics\", how=\"inner\")\n",
    "gdp = pd.merge(gdp, gdp_fips, on=\"FIPS\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Pattern Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cols that will get operated on\n",
    "employment_cols = [\"n<5\", \"n5_9\", \"n10_19\", \"n20_49\", \"n50_99\", \"n100_249\", \"n250_499\", \"n500_999\", \"n1000\", \"n1000_1\", \"n1000_2\", \"n1000_3\", \"n1000_4\"]\n",
    "\n",
    "# Change Ns into 0 and change dtype\n",
    "patterns[employment_cols] = patterns[employment_cols].replace(to_replace=\"N\", value=0)\n",
    "patterns[employment_cols] = patterns[employment_cols].astype(int)\n",
    "\n",
    "# Function to retain biggest noise flag when aggregating\n",
    "def agg_noise(nf):\n",
    "  weight = {\"G\": 1, \"H\": 2, \"J\": 3}\n",
    "\n",
    "  return max(nf, key=lambda letter: weight[letter])\n",
    "  \n",
    "# Group pattern DF by FIPS and NAICS\n",
    "patterns = patterns.groupby([\"FIPS\", \"naics\", \"naics_2\"]).agg({\n",
    "  \"emp_nf\": agg_noise,\n",
    "  \"emp\": \"sum\",\n",
    "  \"ap_nf\": agg_noise,\n",
    "  \"ap\": \"sum\",\n",
    "  \"est\": \"sum\",\n",
    "  \"n<5\": \"sum\",\n",
    "  \"n5_9\": \"sum\",\n",
    "  \"n10_19\": \"sum\",\n",
    "  \"n20_49\": \"sum\",\n",
    "  \"n50_99\": \"sum\",\n",
    "  \"n100_249\": \"sum\",\n",
    "  \"n250_499\": \"sum\",\n",
    "  \"n500_999\": \"sum\",\n",
    "  \"n1000\": \"sum\",\n",
    "  \"n1000_1\": \"sum\",\n",
    "  \"n1000_2\": \"sum\",\n",
    "  \"n1000_3\": \"sum\",\n",
    "  \"n1000_4\": \"sum\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/gdp.pkl\", \"wb\") as handle:\n",
    "  pickle.dump(gdp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"../data/processed/occupation.pkl\", \"wb\") as handle:\n",
    "  pickle.dump(occ, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"../data/processed/patterns.pkl\", \"wb\") as handle:\n",
    "  pickle.dump(patterns, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
